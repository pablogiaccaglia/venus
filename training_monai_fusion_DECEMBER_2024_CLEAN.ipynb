{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VENUS FUSION TRAINING NOTEBOOK\n",
        "\n",
        "This notebook implements fusion-based breast segmentation using the VENUS model with multi-scale patch processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installs & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\ignite\\handlers\\checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MONAI version: 1.6.dev2535\n",
            "Numpy version: 2.0.2\n",
            "Pytorch version: 2.5.1+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 8e677816bfd1fb2ec541d7f951db4caaf210b150\n",
            "MONAI __file__: c:\\Users\\<username>\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\monai\\__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.11\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.24.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 11.3.0\n",
            "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.1+cu121\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 7.0.0\n",
            "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "einops version: 0.8.1\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import tempfile\n",
        "import random\n",
        "import warnings\n",
        "import pprint\n",
        "import copy\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "# Third-party libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import albumentations as A\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skimage import filters\n",
        "from skimage.measure import label as label_fn, regionprops\n",
        "from skimage import morphology\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# MONAI related imports\n",
        "from monai.config import print_config\n",
        "from monai.networks.nets import UNet, SwinUNETR, BasicUNetPlusPlus\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.transforms import (\n",
        "    AsDiscrete, AsDiscreted, EnsureChannelFirstd, Compose, CropForegroundd,\n",
        "    LoadImaged, Orientationd, RandCropByPosNegLabeld, SaveImaged, ScaleIntensityRanged,\n",
        "    Spacingd, Invertd, ResizeWithPadOrCropd, Resized, MapTransform, ScaleIntensityd,\n",
        "    LabelToContourd, ForegroundMaskd, HistogramNormalized, RandFlipd, RandGridDistortiond,\n",
        "    RandHistogramShiftd, RandRotated\n",
        ")\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.utils.type_conversion import convert_to_numpy\n",
        "\n",
        "# PyTorch Lightning related imports\n",
        "import lightning.pytorch as L\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "from lightning.pytorch import seed_everything\n",
        "\n",
        "# Weights & Biases\n",
        "import wandb\n",
        "\n",
        "from natsort import natsorted, ns\n",
        "from PIL import Image\n",
        "from numpy import einsum\n",
        "from torch.utils.data import default_collate\n",
        "import psutil\n",
        "from typing import List, Tuple\n",
        "import monai\n",
        "\n",
        "# Import modules\n",
        "from breast_segmentation.config.settings import config\n",
        "from breast_segmentation.utils.seed import set_deterministic_mode, seed_worker, reseed\n",
        "from breast_segmentation.data.dataset import (\n",
        "    get_image_label_files, create_data_dicts, split_data, create_dataloaders,\n",
        "    PairedDataset, PairedDataLoader\n",
        ")\n",
        "from breast_segmentation.transforms.compose import Preprocess\n",
        "from breast_segmentation.models.fusion_module import BreastFusionModel\n",
        "from breast_segmentation.models.lightning_module import BreastSegmentationModel\n",
        "from breast_segmentation.models.architectures import get_model, VENUS\n",
        "from breast_segmentation.metrics.losses import (\n",
        "    get_loss_function, CrossEntropy2d, compute_class_weight, \n",
        "    AsymmetricUnifiedFocalLoss, CABFL\n",
        ")\n",
        "from breast_segmentation.utils.visualization import (\n",
        "    plot_batch_predictions, plot_training_history\n",
        ")\n",
        "from breast_segmentation.utils.postprocessing import (\n",
        "    remove_far_masses_based_on_largest_mass\n",
        ")\n",
        "\n",
        "from utiils import *\n",
        "from boundaryloss.dataloader import dist_map_transform\n",
        "\n",
        "# Set precision for matmul operations and print MONAI config\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "print_config()\n",
        "\n",
        "# Define converter function to avoid pickling issues with lambda\n",
        "def convert_to_grayscale(image):\n",
        "    \"\"\"Convert PIL image to grayscale - replaces lambda for pickling compatibility.\"\"\"\n",
        "    return image.convert(\"L\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using random seed 200...\n",
            "Batch size: 16\n",
            "Number of workers: 4\n",
            "Checkpoints directory: checkpoints\n",
            "CUDA available: True\n",
            "Device: NVIDIA GeForce RTX 3060\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "batch_size = 16  # Reduced for fusion training\n",
        "num_workers = min(4, os.cpu_count())  # Use multiprocessing for faster data loading\n",
        "checkpoints_dir = config.CHECKPOINTS_DIR\n",
        "get_boundaryloss = True\n",
        "\n",
        "# Ensure checkpoints directory exists\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "g = set_deterministic_mode(config.SEED)\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Number of workers: {num_workers}\")\n",
        "print(f\"Checkpoints directory: {checkpoints_dir}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset statistics:\n",
            "  Training samples: 1202\n",
            "  Validation samples: 117\n",
            "  Test samples: 417\n"
          ]
        }
      ],
      "source": [
        "# Get image and label files\n",
        "dataset_base_path = \"BreaDM/seg\"\n",
        "image_type = \"VIBRANT+C2\"\n",
        "\n",
        "train_images, train_labels = get_image_label_files(\n",
        "    dataset_base_path, \"train\", image_type\n",
        ")\n",
        "val_images, val_labels = get_image_label_files(\n",
        "    dataset_base_path, \"val\", image_type\n",
        ")\n",
        "test_images, test_labels = get_image_label_files(\n",
        "    dataset_base_path, \"test\", image_type\n",
        ")\n",
        "\n",
        "# Create data dictionaries\n",
        "train_dicts = create_data_dicts(train_images, train_labels)\n",
        "val_dicts = create_data_dicts(val_images, val_labels)\n",
        "test_dicts = create_data_dicts(test_images, test_labels)\n",
        "\n",
        "print(f\"Dataset statistics:\")\n",
        "print(f\"  Training samples: {len(train_dicts)}\")\n",
        "print(f\"  Validation samples: {len(val_dicts)}\")\n",
        "print(f\"  Test samples: {len(test_dicts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing and Dataset Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will calculate normalization statistics from data...\n",
            "This allows verification against original pre-computed values:\n"
          ]
        }
      ],
      "source": [
        "# Define subtracted images path prefixes\n",
        "sub_third_images_path_prefixes = (\"VIBRANT+C2\", \"SUB2\")\n",
        "\n",
        "print(\"Will calculate normalization statistics from data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating statistics dataset for global data...\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean and std for global (no patches) data\n",
        "statistics_transforms_no_thorax_third_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='statistics',  \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=False\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"Creating statistics dataset for global data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 1202/1202 [00:39<00:00, 30.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistics dataset and loader created for global data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create statistics dataset and loader for global data\n",
        "statistics_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=statistics_transforms_no_thorax_third_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "statistics_loader_no_thorax_third_sub = DataLoader(\n",
        "    statistics_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "print(\"Statistics dataset and loader created for global data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating mean and std for global data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a752ffcae7734125a669a3b2a49739ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/76 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 10.217766761779785, Standard Deviation: 26.677101135253906\n",
            "Calculated - Global Mean: 10.217766761779785, Global Std: 26.677101135253906\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean and std for global data\n",
        "def get_mean_std_dataloader(dataloader, masked=False):\n",
        "    \"\"\"Calculate mean and std from dataloader.\"\"\"\n",
        "    sum_of_images = 0.0\n",
        "    sum_of_squares = 0.0\n",
        "    num_pixels = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        if batch is not None:\n",
        "            image = batch[\"image\"]\n",
        "      \n",
        "            if masked:\n",
        "                mask = image > 0.0\n",
        "                image = image[mask]\n",
        "      \n",
        "            sum_of_images += image.sum()\n",
        "            sum_of_squares += (image ** 2).sum()\n",
        "            num_pixels += image.numel()\n",
        "        else:\n",
        "            print(\"none batch\")\n",
        "    \n",
        "    mean = sum_of_images / num_pixels\n",
        "    std_dev = (sum_of_squares / num_pixels - mean ** 2) ** 0.5\n",
        "\n",
        "    print(f'Mean: {mean}, Standard Deviation: {std_dev}')\n",
        "    return mean.item(), std_dev.item()\n",
        "\n",
        "print(\"Calculating mean and std for global data...\")\n",
        "mean_no_thorax_third_sub_calc, std_no_thorax_third_sub_calc = get_mean_std_dataloader(statistics_loader_no_thorax_third_sub)\n",
        "print(f\"Calculated - Global Mean: {mean_no_thorax_third_sub_calc}, Global Std: {std_no_thorax_third_sub_calc}\")\n",
        "\n",
        "# Use calculated or pre-computed values\n",
        "mean_no_thorax_third_sub, std_no_thorax_third_sub = mean_no_thorax_third_sub_calc, std_no_thorax_third_sub_calc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating statistics dataset for patches data...\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean and std for patches data\n",
        "statistics_transforms_patches_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='statistics', \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        get_patches=True,\n",
        "        get_boundaryloss=False\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"Creating statistics dataset for patches data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 1202/1202 [01:57<00:00, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating mean and std for patches data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d0832dbf09e4fa693d0dd9a774416eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/76 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 20.630815505981445, Standard Deviation: 35.328887939453125\n",
            "Calculated - Patches Mean: 20.630815505981445, Patches Std: 35.328887939453125\n"
          ]
        }
      ],
      "source": [
        "statistics_ds_patches_sub = CacheDataset(\n",
        "     data=train_dicts, \n",
        "     transform=statistics_transforms_patches_sub,\n",
        "     num_workers=num_workers\n",
        " )\n",
        "\n",
        "statistics_loader_patches_sub = DataLoader(\n",
        "     statistics_ds_patches_sub, \n",
        "     batch_size=batch_size, \n",
        "     worker_init_fn=seed_worker,\n",
        "     generator=g, \n",
        "     shuffle=False, \n",
        "     drop_last=False\n",
        " )\n",
        "\n",
        "print(\"Calculating mean and std for patches data...\")\n",
        "mean_patches_sub_calc, std_patches_sub_calc = get_mean_std_dataloader(statistics_loader_patches_sub)\n",
        "print(f\"Calculated - Patches Mean: {mean_patches_sub_calc}, Patches Std: {std_patches_sub_calc}\")\n",
        "\n",
        "# Set final values\n",
        "mean_patches_sub, std_patches_sub = mean_patches_sub_calc, std_patches_sub_calc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final transforms created using calculated statistics\n"
          ]
        }
      ],
      "source": [
        "# Create final transforms using calculated statistics\n",
        "test_transforms_no_thorax_third_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='test',  \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_no_thorax_third_sub, \n",
        "        divisor=std_no_thorax_third_sub, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "train_transforms_no_thorax_third_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='train', \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_no_thorax_third_sub, \n",
        "        divisor=std_no_thorax_third_sub, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "# Create transforms for patches data\n",
        "train_transforms_patches_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='train', \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_patches_sub, \n",
        "        divisor=std_patches_sub, \n",
        "        get_patches=True,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transforms_patches_sub = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=convert_to_grayscale)\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='test',  \n",
        "        dataset=\"BRADM\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_patches_sub, \n",
        "        divisor=std_patches_sub, \n",
        "        get_patches=True,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"Final transforms created using calculated statistics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 1202/1202 [00:45<00:00, 26.61it/s]\n",
            "Loading dataset: 100%|██████████| 117/117 [00:04<00:00, 28.62it/s]\n",
            "Loading dataset: 100%|██████████| 417/417 [00:14<00:00, 28.94it/s]\n",
            "Loading dataset: 100%|██████████| 1202/1202 [01:57<00:00, 10.19it/s]\n",
            "Loading dataset: 100%|██████████| 117/117 [00:11<00:00,  9.76it/s]\n",
            "Loading dataset: 100%|██████████| 417/417 [00:36<00:00, 11.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets created for both global and patches data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create datasets for both global and patches data\n",
        "train_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=train_transforms_no_thorax_third_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=val_dicts, \n",
        "    transform=test_transforms_no_thorax_third_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=test_dicts, \n",
        "    transform=test_transforms_no_thorax_third_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "train_ds_patches_sub = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=train_transforms_patches_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_ds_patches_sub = CacheDataset(\n",
        "    data=val_dicts, \n",
        "    transform=test_transforms_patches_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_ds_patches_sub = CacheDataset(\n",
        "    data=test_dicts, \n",
        "    transform=test_transforms_patches_sub,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "print(\"Datasets created for both global and patches data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Fusion DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using random seed 200...\n",
            "Fusion dataloaders created\n"
          ]
        }
      ],
      "source": [
        "# Reseed before creating dataloaders\n",
        "g = reseed()\n",
        "\n",
        "# Create fusion dataloaders that combine global and patches data\n",
        "train_loader_fusion_sub = PairedDataLoader(\n",
        "    train_ds_no_thorax_third_sub, \n",
        "    train_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=True, \n",
        "    drop_last=False, \n",
        "    num_workers=num_workers,\n",
        "    augment=False,\n",
        ")\n",
        "\n",
        "val_loader_fusion_sub = PairedDataLoader(\n",
        "    val_ds_no_thorax_third_sub, \n",
        "    val_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False, \n",
        "    num_workers=num_workers,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "test_loader_fusion_sub = PairedDataLoader(\n",
        "    test_ds_no_thorax_third_sub, \n",
        "    test_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False, \n",
        "    num_workers=num_workers,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "print(\"Fusion dataloaders created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training VENUS Fusion Model with CABFL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using random seed 200...\n",
            "Initialized SurfaceLossBinary with [1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\pabli\\_netrc\n",
            "wandb: Currently logged in as: pablo-giaccaglia to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "creating run (0.2s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>.\\wandb\\run-20250905_222003-cg2oh34k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pablo-giaccaglia/Tesi-final/runs/cg2oh34k' target=\"_blank\">treasured-salad-256</a></strong> to <a href='https://wandb.ai/pablo-giaccaglia/Tesi-final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/pablo-giaccaglia/Tesi-final' target=\"_blank\">https://wandb.ai/pablo-giaccaglia/Tesi-final</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/pablo-giaccaglia/Tesi-final/runs/cg2oh34k' target=\"_blank\">https://wandb.ai/pablo-giaccaglia/Tesi-final/runs/cg2oh34k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:701: Checkpoint directory C:\\Users\\pabli\\Desktop\\venus\\checkpoints exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type  | Params | Mode \n",
            "------------------------------------------\n",
            "0 | model   | VENUS | 21.7 M | train\n",
            "1 | loss_fn | CABFL | 0      | train\n",
            "------------------------------------------\n",
            "21.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "21.7 M    Total params\n",
            "86.860    Total estimated model params size (MB)\n",
            "331       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22c6fde651dc4787be5e2c317a0673e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        }
      ],
      "source": [
        "g = reseed()\n",
        "\n",
        "# Create VENUS fusion model with CABFL loss\n",
        "model_fusion_sub_cabl = BreastFusionModel(\n",
        "    arch=\"venus\",\n",
        "    encoder_name=None,\n",
        "    in_channels=1,\n",
        "    out_classes=1,\n",
        "    batch_size=batch_size,\n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub) // batch_size,\n",
        "    use_boundary_loss=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.4, \"gamma\": 0.1},\n",
        "    base_channels=64,\n",
        "    use_simple_fusion=False,\n",
        "    use_decoder_attention=True\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_fusion_sub_cabl = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='venus-fusion-cabl-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "wandb.login(key=\"2bc18e4744fb0771a16fd009b7aa2c98c79efc49\")\n",
        "wandb_logger = WandbLogger(project='Tesi-final', log_model=False)\n",
        "\n",
        "trainer_fusion_sub_cabl = L.Trainer(\n",
        "    logger=wandb_logger,\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es, cc_fusion_sub_cabl],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=False\n",
        ")\n",
        "\n",
        "trainer_fusion_sub_cabl.fit(\n",
        "    model_fusion_sub_cabl,\n",
        "    train_dataloaders=train_loader_fusion_sub,\n",
        "    val_dataloaders=val_loader_fusion_sub\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model and test\n",
        "model_fusion_sub_cabl = BreastFusionModel.load_from_checkpoint(\n",
        "    cc_fusion_sub_cabl.best_model_path,\n",
        "    use_boundary_loss=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.4, \"gamma\": 0.1}\n",
        ")\n",
        "test_metrics = trainer_fusion_sub_cabl.test(\n",
        "    model_fusion_sub_cabl, \n",
        "    dataloaders=test_loader_fusion_sub, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training VENUS Fusion Model with Simple Fusion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "\n",
        "# Create VENUS fusion model with simple fusion and smaller base channels\n",
        "model_fusion_sub_cabl_simple = BreastFusionModel(\n",
        "    arch=\"venus\",\n",
        "    encoder_name=None,\n",
        "    in_channels=1,\n",
        "    out_classes=1,\n",
        "    batch_size=batch_size,\n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub) // batch_size,\n",
        "    use_boundary_loss=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.4, \"gamma\": 0.1},\n",
        "    base_channels=16,\n",
        "    use_simple_fusion=True,\n",
        "    use_decoder_attention=True\n",
        ")\n",
        "\n",
        "es_simple = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_fusion_sub_cabl_simple = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='venus-fusion-simple-cabl-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "wandb.login(key=\"2bc18e4744fb0771a16fd009b7aa2c98c79efc49\")\n",
        "wandb_logger_simple = WandbLogger(project='Tesi-final', log_model=False)\n",
        "\n",
        "trainer_fusion_sub_cabl_simple = L.Trainer(\n",
        "    logger=wandb_logger_simple,\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_simple, cc_fusion_sub_cabl_simple],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=False\n",
        ")\n",
        "\n",
        "trainer_fusion_sub_cabl_simple.fit(\n",
        "    model_fusion_sub_cabl_simple,\n",
        "    train_dataloaders=train_loader_fusion_sub,\n",
        "    val_dataloaders=val_loader_fusion_sub\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best simple fusion model and test\n",
        "model_fusion_sub_cabl_simple = BreastFusionModel.load_from_checkpoint(\n",
        "    cc_fusion_sub_cabl_simple.best_model_path,\n",
        "    base_channels=16,\n",
        "    use_boundary_loss=True,\n",
        "    use_simple_fusion=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.4, \"gamma\": 0.1}\n",
        ")\n",
        "test_metrics_simple = trainer_fusion_sub_cabl_simple.test(\n",
        "    model_fusion_sub_cabl_simple, \n",
        "    dataloaders=test_loader_fusion_sub, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_simple[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_fusion_sub_cabl_simple.save_checkpoint(\"VENUS-FUSION-SIMPLE-CABL.ckpt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training ResNet with Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "# Create individual loaders for patches data (used by ResNet baseline)\n",
        "train_loader_patches_sub = DataLoader(\n",
        "    train_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=True, \n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "val_loader_patches_sub = DataLoader(\n",
        "    val_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_loader_patches_sub = DataLoader(\n",
        "    test_ds_patches_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = \"resnet18\"\n",
        "model_resnet_patches_cabl = BreastSegmentationModel(\n",
        "    arch=\"UNet\",\n",
        "    encoder_name=ENCODER_NAME,\n",
        "    in_channels=1,\n",
        "    out_classes=1,\n",
        "    batch_size=batch_size,\n",
        "    len_train_loader=len(train_ds_patches_sub) // batch_size,\n",
        "    use_boundary_loss=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.7, \"gamma\": 0.4}\n",
        ")\n",
        "\n",
        "es_resnet = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_resnet_cabl = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='resnet18-patches-cabl-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "wandb.login(key=\"2bc18e4744fb0771a16fd009b7aa2c98c79efc49\")\n",
        "wandb_logger_resnet = WandbLogger(project='Tesi-final', log_model=False)\n",
        "\n",
        "trainer_resnet_cabl = L.Trainer(\n",
        "    logger=wandb_logger_resnet,\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_resnet, cc_resnet_cabl],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=False\n",
        ")\n",
        "\n",
        "trainer_resnet_cabl.fit(\n",
        "    model_resnet_patches_cabl,\n",
        "    train_dataloaders=train_loader_patches_sub,\n",
        "    val_dataloaders=val_loader_patches_sub\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best ResNet patches model and test\n",
        "model_resnet_patches_cabl = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_resnet_cabl.best_model_path,\n",
        "    strict=True,\n",
        "    use_boundary_loss=True,\n",
        "    loss_function=\"cabfl\",\n",
        "    loss_kwargs={\"idc\": [1], \"weight_aufl\": 0.5, \"delta\": 0.4, \"gamma\": 0.1}\n",
        ")\n",
        "test_metrics_resnet = trainer_resnet_cabl.test(\n",
        "    model_resnet_patches_cabl, \n",
        "    dataloaders=test_loader_patches_sub, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_resnet[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_resnet_cabl.save_checkpoint(\"RESNET18-PATCHES-BREADM-CABL.ckpt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of all results\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL RESULTS SUMMARY - FUSION MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "models_results = [\n",
        "    (\"VENUS Fusion (Full)\", test_metrics[0] if 'test_metrics' in locals() else None),\n",
        "    (\"VENUS Fusion (Simple)\", test_metrics_simple[0] if 'test_metrics_simple' in locals() else None),\n",
        "    (\"ResNet18-Patches\", test_metrics_resnet[0] if 'test_metrics_resnet' in locals() else None)\n",
        "]\n",
        "\n",
        "for model_name, results in models_results:\n",
        "    if results:\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        key_metrics = [\n",
        "            'test_per_dataset_dice', 'test_per_dataset_iou', \n",
        "            'test_mean_dice_per_dataset', 'test_mean_iou_per_dataset',\n",
        "            'test_accuracy', 'test_precision', 'test_recall'\n",
        "        ]\n",
        "        for metric in key_metrics:\n",
        "            if metric in results:\n",
        "                print(f\"  {metric}: {results[metric]:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\n{model_name}: Not trained\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FUSION NOTEBOOK COMPLETED\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venus-nCPuPPcI-py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
