{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset-Aware Inference Notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import monai\n",
        "import matplotlib.pyplot as plt\n",
        "import pprint\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# MONAI imports\n",
        "from monai.data import CacheDataset, DataLoader\n",
        "\n",
        "# Import custom modules\n",
        "from breast_segmentation.transforms import Preprocess\n",
        "from breast_segmentation.models import BreastSegmentationModel, BreastFusionModel\n",
        "from breast_segmentation.metrics.losses import (\n",
        "    CABFL, SurfaceLossBinary, AsymmetricUnifiedFocalLoss, \n",
        "    AsymmetricFocalLoss, AsymmetricFocalTverskyLoss\n",
        ")\n",
        "from breast_segmentation.inference import (\n",
        "    test_dataset_aware_no_patches,\n",
        "    test_dataset_aware_fusion,\n",
        "    test_dataset_aware_ensemble\n",
        ")\n",
        "from breast_segmentation.utils import (\n",
        "    get_patient_ids, get_image_label_files_patient_aware, reverse_transformations,\n",
        "    visualize_predictions, visualize_volume_predictions\n",
        ")\n",
        "from breast_segmentation.data import custom_collate_no_patches, custom_collate\n",
        "from breast_segmentation.metrics import filter_masses\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
        "\n",
        "# Register loss classes for checkpoint loading\n",
        "sys.modules['__main__'].CABFL = CABFL\n",
        "sys.modules['__main__'].SurfaceLossBinary = SurfaceLossBinary\n",
        "sys.modules['__main__'].AsymmetricUnifiedFocalLoss = AsymmetricUnifiedFocalLoss\n",
        "sys.modules['__main__'].AsymmetricFocalLoss = AsymmetricFocalLoss\n",
        "sys.modules['__main__'].AsymmetricFocalTverskyLoss = AsymmetricFocalTverskyLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "SEED = 200\n",
        "USE_SUBTRACTED = True\n",
        "\n",
        "# Data paths\n",
        "BREADM_DIR = \"./BreaDM\"\n",
        "TEST_DIR = os.path.join(BREADM_DIR, \"seg/\")\n",
        "dataset_base_path = TEST_DIR \n",
        "CHECKPOINTS_DIR = \"./checkpoints/breadm-dataset\"\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Test Patient IDs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get test patient IDs\n",
        "x_test = get_patient_ids(TEST_DIR, split='test')\n",
        "print(f\"Number of test patients: {len(x_test)}\")\n",
        "print(f\"Test patient IDs: {x_test[:5]}...\")  # Show first 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-computed statistics (from training)\n",
        "GLOBAL_MEAN = 10.217766761779785\n",
        "GLOBAL_STD = 26.677101135253906\n",
        "PATCHES_MEAN =  20.630817413330078\n",
        "PATCHES_STD = 35.328887939453125\n",
        "\n",
        "# Create patient-aware datasets\n",
        "datasets = {}\n",
        "for patient_id in tqdm(x_test, desc=\"Creating patient datasets\"):\n",
        "    # Get files for this patient\n",
        "    image_files, label_files = get_image_label_files_patient_aware(\n",
        "        dataset_base_path=\"BreaDM/seg\", \n",
        "        split=\"test\", \n",
        "        image_type=\"VIBRANT+C2\", \n",
        "        patient_id=patient_id\n",
        "    )\n",
        "    \n",
        "    data_dicts = [\n",
        "        {\"image\": img, \"label\": lbl, \"subtracted\": img}\n",
        "        for img, lbl in zip(image_files, label_files)\n",
        "    ]\n",
        "    \n",
        "    # Define transforms following rebuttal notebook pattern\n",
        "    test_transforms_no_thorax_sub = monai.transforms.Compose([\n",
        "        monai.transforms.LoadImaged(keys=[\"image\", \"label\"], \n",
        "                                   image_only=False, \n",
        "                                   reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))),\n",
        "        monai.transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "        Preprocess(keys=None, \n",
        "                  mode='test',  \n",
        "                  dataset=\"BRADM\", \n",
        "                  subtracted_images_path_prefixes=(\"VIBRANT+C2\", \"SUB2\"), \n",
        "                  subtrahend=GLOBAL_MEAN, \n",
        "                  divisor=GLOBAL_STD, \n",
        "                  get_patches=False,\n",
        "                  get_boundaryloss=False)\n",
        "    ])\n",
        "    \n",
        "    test_transforms_patches_sub = monai.transforms.Compose([\n",
        "        monai.transforms.LoadImaged(keys=[\"image\", \"label\"], \n",
        "                                   image_only=False, \n",
        "                                   reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))),\n",
        "        monai.transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "        Preprocess(keys=None, \n",
        "                  mode='test',  \n",
        "                  dataset=\"BRADM\", \n",
        "                  subtracted_images_path_prefixes=(\"VIBRANT+C2\", \"SUB2\"), \n",
        "                  subtrahend=PATCHES_MEAN, \n",
        "                  divisor=PATCHES_STD, \n",
        "                  get_patches=True,\n",
        "                  get_boundaryloss=False)\n",
        "    ])\n",
        "    \n",
        "    # No thorax dataset (whole images)\n",
        "    no_thorax_test_ds = CacheDataset(\n",
        "        data=data_dicts,\n",
        "        transform=test_transforms_no_thorax_sub,\n",
        "        cache_rate=1.0,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n",
        "    \n",
        "    # Patches dataset  \n",
        "    patches_test_ds = CacheDataset(\n",
        "        data=data_dicts,\n",
        "        transform=test_transforms_patches_sub,\n",
        "        cache_rate=1.0,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n",
        "    \n",
        "    datasets[patient_id] = {\n",
        "        'no_thorax_sub_test_ds': no_thorax_test_ds,\n",
        "        'patches_sub_test_ds': patches_test_ds\n",
        "    }\n",
        "\n",
        "print(\"Patient datasets created successfully!\")\n",
        "\n",
        "# Define data_transforms dictionary for visualization function\n",
        "data_transforms = {\n",
        "    'no_thorax_sub_test_ds': test_transforms_no_thorax_sub,\n",
        "    'no_thorax_sub_thorax_test_ds': test_transforms_no_thorax_sub,  # Same transform\n",
        "    'patches_sub_test_ds': test_transforms_patches_sub\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Checkpoint Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_paths = {\n",
        "    # VENUS fusion models\n",
        "    'venus_tiny': f'{CHECKPOINTS_DIR}/venus-tiny-best.ckpt',\n",
        "    \n",
        "    # Baseline models\n",
        "    'unetplusplus': f'{CHECKPOINTS_DIR}/unetplusplus_model.ckpt',\n",
        "    'skinny': f'{CHECKPOINTS_DIR}/skinny_model.ckpt',\n",
        "    'resnet50': f'{CHECKPOINTS_DIR}/resnet50.ckpt',\n",
        "    'fcn': f'{CHECKPOINTS_DIR}/unetplusplus_model.ckpt',  \n",
        "    'segnet': f'{CHECKPOINTS_DIR}/segnet_model_large.ckpt',\n",
        "    'swin': f'{CHECKPOINTS_DIR}/swin_model.ckpt',\n",
        "    \n",
        "    # Patches models\n",
        "    'resnet50_patches': f'{CHECKPOINTS_DIR}/resnet50-patches.ckpt',\n",
        "    'resnet18_patches': f'{CHECKPOINTS_DIR}/resnet18-patches.ckpt',\n",
        "    'unetplusplus_patches': f'{CHECKPOINTS_DIR}/unetplusplus-patches-cabfl.ckpt',\n",
        "}\n",
        "\n",
        "# Check which models are available\n",
        "print(\"Available models:\")\n",
        "for name, path in model_paths.items():\n",
        "    if os.path.exists(path):\n",
        "        print(f\"  âœ“ {name}: {path}\")\n",
        "    else:\n",
        "        print(f\"  âœ— {name}: {path} (not found)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test VENUS Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: venus-tiny-best.ckpt\n",
        "if os.path.exists(model_paths['venus_tiny']):\n",
        "    print(\"Testing VENUS Tiny ...\")\n",
        "    scores_for_statistics_fusion_tiny = test_dataset_aware_fusion(\n",
        "        model_path=model_paths['venus_tiny'],\n",
        "        patient_ids=x_test,\n",
        "        datasets=datasets,\n",
        "        whole_dataset_key=\"no_thorax_sub_test_ds\",\n",
        "        patches_dataset_key=\"patches_sub_test_ds\",\n",
        "        use_simple_fusion=False,\n",
        "        use_decoder_attention=True,\n",
        "        strict=True,\n",
        "        filter=False,\n",
        "        subtracted=True,\n",
        "        get_scores_for_statistics=False,\n",
        "        get_only_masses=False,\n",
        "        base_channels=16\n",
        "    )\n",
        "    print(\"\\nVENUS Tiny:\")\n",
        "    pp.pprint(scores_for_statistics_fusion_tiny)\n",
        "else:\n",
        "    print(\"venus-tiny.ckpt not found.\")\n",
        "    scores_for_statistics_fusion_tiny = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Baseline Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test baseline models (6 tests)\n",
        "baseline_tests = [\n",
        "    ('unetplusplus', 'UNet++', 'unetplusplus'),\n",
        "    ('skinny', 'SkinnyNet', 'skinny') ,\n",
        "    ('resnet50', 'ResNet50', 'resnet50'),\n",
        "    ('fcn', 'FCN', 'unetplusplus'), \n",
        "    ('segnet', 'SegNet', 'segnet'),\n",
        "    ('swin', 'Swin-UNETR', 'swin_unetr')\n",
        "]\n",
        "\n",
        "baseline_results = {}\n",
        "for model_key, model_name, arch_name in baseline_tests:\n",
        "    if os.path.exists(model_paths[model_key]):\n",
        "        print(f\"Testing {model_name} model...\")\n",
        "        result = test_dataset_aware_no_patches(\n",
        "            model_path=model_paths[model_key],\n",
        "            patient_ids=x_test,\n",
        "            datasets=datasets,\n",
        "            dataset_key=\"no_thorax_sub_test_ds\",\n",
        "            filter=False,\n",
        "            get_scores_for_statistics=False,\n",
        "            get_only_masses=False,\n",
        "            arch_name=arch_name,\n",
        "            strict=True,\n",
        "            subtracted=True\n",
        "        )\n",
        "        baseline_results[model_key] = result\n",
        "        print(f\"\\n{model_name} Results:\")\n",
        "        pp.pprint(result)\n",
        "    else:\n",
        "        print(f\"{model_paths[model_key]} not found.\")\n",
        "        baseline_results[model_key] = None\n",
        "\n",
        "print(f\"\\nCompleted {len([r for r in baseline_results.values() if r is not None])} baseline model tests.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Ensemble Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ensemble_tests = [\n",
        "    ('venus_tiny', 'unetplusplus_patches', False, 16, 'VENUS Tiny + UNet++ patches'),\n",
        "    ('venus_tiny', 'unetplusplus_patches', True, 16, 'VENUS Tiny + UNet++ patches (filtered)'),\n",
        "    \n",
        "    ('venus_tiny', 'resnet18_patches', False, 16, 'VENUS Tiny + ResNet18 patches'),\n",
        "    ('venus_tiny', 'resnet18_patches', True, 16, 'VENUS Tiny + ResNet18 patches (filtered)'),\n",
        "]\n",
        "\n",
        "ensemble_results = {}\n",
        "for whole_key, patches_key, use_filter, base_channels, description in ensemble_tests:\n",
        "    if os.path.exists(model_paths[whole_key]) and os.path.exists(model_paths[patches_key]):\n",
        "        print(f\"Testing Ensemble: {description}...\")\n",
        "        \n",
        "        result = test_dataset_aware_ensemble(\n",
        "            model_whole_path=model_paths[whole_key],\n",
        "            model_patches_path=model_paths[patches_key],\n",
        "            patient_ids=x_test,\n",
        "            datasets=datasets,\n",
        "            whole_dataset_key=\"no_thorax_sub_test_ds\",\n",
        "            patches_dataset_key=\"patches_sub_test_ds\",\n",
        "            filter=use_filter,\n",
        "            get_scores_for_statistics=False,\n",
        "            get_only_masses=False,\n",
        "            subtracted=True,\n",
        "            base_channels=base_channels\n",
        "        )\n",
        "        \n",
        "        ensemble_key = f\"{whole_key}+{patches_key}{'_filtered' if use_filter else ''}\"\n",
        "        ensemble_results[ensemble_key] = result\n",
        "        print(f\"\\n{description} Results:\")\n",
        "        pp.pprint(result)\n",
        "    else:\n",
        "        print(f\"Required models not found for ensemble: {description}\")\n",
        "        ensemble_key = f\"{whole_key}+{patches_key}{'_filtered' if use_filter else ''}\"\n",
        "        ensemble_results[ensemble_key] = None\n",
        "\n",
        "print(f\"\\nCompleted {len([r for r in ensemble_results.values() if r is not None])} ensemble model tests.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venus-nCPuPPcI-py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
