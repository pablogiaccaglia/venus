{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETUP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installs & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\ignite\\handlers\\checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MONAI version: 1.6.dev2535\n",
            "Numpy version: 2.0.2\n",
            "Pytorch version: 2.5.1+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 8e677816bfd1fb2ec541d7f951db4caaf210b150\n",
            "MONAI __file__: c:\\Users\\<username>\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\monai\\__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.11\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.24.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 11.3.0\n",
            "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.1+cu121\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 7.0.0\n",
            "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "einops version: 0.8.1\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import tempfile\n",
        "import random\n",
        "import warnings\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "# Third-party libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import albumentations as A\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skimage import filters\n",
        "from skimage.measure import label as label_fn, regionprops\n",
        "from skimage import morphology\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# MONAI related imports\n",
        "from monai.config import print_config\n",
        "from monai.networks.nets import UNet, SwinUNETR, BasicUNetPlusPlus\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.transforms import (\n",
        "    AsDiscrete, AsDiscreted, EnsureChannelFirstd, Compose, CropForegroundd,\n",
        "    LoadImaged, Orientationd, RandCropByPosNegLabeld, SaveImaged, ScaleIntensityRanged,\n",
        "    Spacingd, Invertd, ResizeWithPadOrCropd, Resized, MapTransform, ScaleIntensityd,\n",
        "    LabelToContourd, ForegroundMaskd, HistogramNormalized, RandFlipd, RandGridDistortiond,\n",
        "    RandHistogramShiftd, RandRotated\n",
        ")\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.utils.type_conversion import convert_to_numpy\n",
        "\n",
        "# PyTorch Lightning related imports\n",
        "import lightning.pytorch as L\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from lightning.pytorch import seed_everything\n",
        "\n",
        "from natsort import natsorted, ns\n",
        "from PIL import Image\n",
        "from numpy import einsum\n",
        "from torch.utils.data import default_collate\n",
        "import psutil\n",
        "from typing import List\n",
        "import monai\n",
        "\n",
        "# Import modules\n",
        "from breast_segmentation.config.settings import config\n",
        "from breast_segmentation.utils.seed import set_deterministic_mode, seed_worker, reseed\n",
        "from breast_segmentation.data.dataset import (\n",
        "    get_image_label_files, create_data_dicts, split_data, create_dataloaders, get_dataset_base_path\n",
        ")\n",
        "from breast_segmentation.data import custom_collate_no_patches\n",
        "from breast_segmentation.transforms.compose import Preprocess\n",
        "from breast_segmentation.models.lightning_module import BreastSegmentationModel\n",
        "from breast_segmentation.models.architectures import get_model\n",
        "from breast_segmentation.metrics.losses import get_loss_function, CrossEntropy2d, compute_class_weight, AsymmetricUnifiedFocalLoss\n",
        "from breast_segmentation.utils.visualization import (\n",
        "    plot_batch_predictions, plot_training_history\n",
        ")\n",
        "from breast_segmentation.utils.postprocessing import (\n",
        "    remove_far_masses_based_on_largest_mass\n",
        ")\n",
        "\n",
        "from boundaryloss.dataloader import dist_map_transform\n",
        "\n",
        "from breast_segmentation.data.private_dataset import (\n",
        "    PATIENT_INFO, get_filenames, get_train_val_test_dicts, PATIENTS_TO_EXCLUDE\n",
        ")\n",
        "\n",
        "\n",
        "# Import additional loss functions used in original\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "\n",
        "# Set precision for matmul operations and print MONAI config\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "print_config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial patients from PATIENT_INFO: 3\n",
            "Patients to exclude: ['CMG0948', 'IM0544(1,5)B-merged', 'D2MP8(VR)', 'VC0285(1,5)B-merged']\n",
            "Patients after exclusion: 3\n",
            "Creating data dictionaries with filtering logic...\n",
            "\n",
            "data:\n",
            "  Training samples: 126\n",
            "  Validation samples: 228\n",
            "  Test samples: 212\n"
          ]
        }
      ],
      "source": [
        "patient_ids = list(PATIENT_INFO.keys())[:3]\n",
        "\n",
        "# Apply exclusions (exactly as in reference notebook)\n",
        "print(f\"Initial patients from PATIENT_INFO: {len(patient_ids)}\")\n",
        "print(f\"Patients to exclude: {PATIENTS_TO_EXCLUDE}\")\n",
        "patient_ids = [pid for pid in patient_ids if pid not in PATIENTS_TO_EXCLUDE]\n",
        "print(f\"Patients after exclusion: {len(patient_ids)}\")\n",
        "\n",
        "# Data split using original train_test_split\n",
        "SEED = 200 \n",
        "dataset_base_path = \"Dataset-arrays-4-FINAL\"\n",
        "x_train_val, x_test = train_test_split(patient_ids, test_size=0.2, random_state=SEED)\n",
        "x_train, x_val = train_test_split(x_train_val, test_size=0.25, random_state=SEED)\n",
        "\n",
        "\n",
        "print(\"Creating data dictionaries with filtering logic...\")\n",
        "train_dicts, val_dicts, test_dicts = get_train_val_test_dicts(dataset_base_path, x_train, x_val, x_test)\n",
        "\n",
        "print(f\"\\ndata:\")\n",
        "print(f\"  Training samples: {len(train_dicts)}\")\n",
        "print(f\"  Validation samples: {len(val_dicts)}\")\n",
        "print(f\"  Test samples: {len(test_dicts)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using random seed 200...\n",
            "Batch size: 24\n",
            "Number of workers: 24\n",
            "Checkpoints directory: checkpoints\n",
            "CUDA available: True\n",
            "Device: NVIDIA GeForce RTX 3060\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "batch_size = 24\n",
        "num_workers = os.cpu_count()\n",
        "checkpoints_dir = config.CHECKPOINTS_DIR\n",
        "get_boundaryloss = False\n",
        "\n",
        "# Ensure checkpoints directory exists\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "g = set_deterministic_mode(config.SEED)\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Number of workers: {num_workers}\")\n",
        "print(f\"Checkpoints directory: {checkpoints_dir}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Private Dataset Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistics transforms created for private dataset (EXACT as reference)\n"
          ]
        }
      ],
      "source": [
        "# Define subtracted images path prefixes (CRITICAL: Private dataset DOES use subtracted images)\n",
        "sub_third_images_path_prefixes = (\"Dataset-arrays-4-FINAL\", \"Dataset-arrays-FINAL\")\n",
        "\n",
        "# Create transforms for statistics calculation (EXACT as reference notebook)\n",
        "statistics_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.NumpyReader()  # EXACT: Use NumpyReader like reference\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='statistics',  \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        get_patches=False\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"Statistics transforms created for private dataset (EXACT as reference)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 126/126 [00:04<00:00, 28.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistics dataset and loader created (with custom collate as reference)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create dataset for statistics calculation\n",
        "statistics_ds_private = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=statistics_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "statistics_loader_private = DataLoader(\n",
        "    statistics_ds_private, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  # EXACT: Use custom collate as reference\n",
        ")\n",
        "\n",
        "print(\"Statistics dataset and loader created (with custom collate as reference)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6552c90267946ed8cd66fa5bb9a8a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 19.024364471435547, Standard Deviation: 173.03067016601562\n",
            "Calculated - Mean: 19.024364471435547, Standard Deviation: 173.03067016601562\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean and std for normalization\n",
        "def get_mean_std_dataloader(dataloader, masked=False):\n",
        "    \"\"\"Calculate mean and std from dataloader.\"\"\"\n",
        "    sum_of_images = 0.0\n",
        "    sum_of_squares = 0.0\n",
        "    num_pixels = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        if batch is not None:\n",
        "            image = batch[\"image\"]\n",
        "      \n",
        "            if masked:\n",
        "                mask = image > 0.0\n",
        "                image = image[mask]\n",
        "      \n",
        "            sum_of_images += image.sum()\n",
        "            sum_of_squares += (image ** 2).sum()\n",
        "            num_pixels += image.numel()\n",
        "        else:\n",
        "            print(\"batch is None\")\n",
        "    \n",
        "    mean = sum_of_images / num_pixels\n",
        "    std_dev = (sum_of_squares / num_pixels - mean ** 2) ** 0.5\n",
        "\n",
        "    print(f'Mean: {mean}, Standard Deviation: {std_dev}')\n",
        "    return mean.item(), std_dev.item()\n",
        "\n",
        "mean_private, std_private = get_mean_std_dataloader(statistics_loader_private)\n",
        "print(f\"Calculated - Mean: {mean_private}, Standard Deviation: {std_private}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final transforms with calculated statistics\n",
        "test_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='test',  \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_private, \n",
        "        divisor=std_private, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "train_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='train', \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_private, \n",
        "        divisor=std_private, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 126/126 [00:04<00:00, 26.63it/s]\n",
            "Loading dataset: 100%|██████████| 228/228 [00:08<00:00, 26.88it/s]\n",
            "Loading dataset: 100%|██████████| 212/212 [00:07<00:00, 28.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create datasets (use original naming convention)\n",
        "train_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=train_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=val_dicts, \n",
        "    transform=test_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=test_dicts, \n",
        "    transform=test_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "no_thorax_sub_train_loader = DataLoader(\n",
        "    train_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=True, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  # EXACT: Use custom collate as reference\n",
        ")\n",
        "\n",
        "no_thorax_sub_val_loader = DataLoader(\n",
        "    val_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  # EXACT: Use custom collate as reference\n",
        ")\n",
        "\n",
        "no_thorax_sub_test_loader = DataLoader(\n",
        "    test_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  # EXACT: Use custom collate as reference\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([24, 1, 256, 256])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize sample batch\n",
        "i = next(iter(no_thorax_sub_train_loader))[\"image\"]\n",
        "print(i.shape)\n",
        "plt.imshow(i[0,0], cmap='gray')\n",
        "plt.title('Sample from training data')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training FCN-FFNET\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using random seed 200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "fcn_ffnet_model = BreastSegmentationModel(\n",
        "    arch=\"fcn_ffnet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\",  # Use string instead of instantiating the class\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256, \n",
        "    in_channels=1, \n",
        "    out_classes=1, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_fcn_ffnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='unet-clahe--mit2-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "trainer_fcn_ffnet_model = L.Trainer(\n",
        "    devices = 1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es, cc_fcn_ffnet_model],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:701: Checkpoint directory C:\\Users\\pabli\\Desktop\\venus\\checkpoints exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type     | Params | Mode \n",
            "-------------------------------------------\n",
            "0 | model | FcnnFnet | 17.3 M | train\n",
            "-------------------------------------------\n",
            "17.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "17.3 M    Total params\n",
            "69.049    Total estimated model params size (MB)\n",
            "103       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4b7a4b069ce4ae9a3cdf92a6e4251f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\metrics\\evaluation.py:386: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dice_score = torch.tensor(compute_dice_score_single(y_true_flat, y_pred_flat, class_id, exclude_empty)).float()\n",
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40a249ea7c99480189330f05a423ffb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdbe7047f582462e9a968e20a3b6671b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29b5047196334cc2b18906d2d1b213aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'tb_frame'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:49\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:598\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    592\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    594\u001b[0m     ckpt_path,\n\u001b[0;32m    595\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m )\n\u001b[1;32m--> 598\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1011\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1011\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1055\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:153\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:398\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    396\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_model_zero_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:145\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:437\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    432\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    436\u001b[0m )\n\u001b[1;32m--> 437\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:329\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 329\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\models\\lightning_module.py:281\u001b[0m, in \u001b[0;36mBreastSegmentationModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch:\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\models\\lightning_module.py:185\u001b[0m, in \u001b[0;36mBreastSegmentationModel.step\u001b[1;34m(self, batch, batch_idx, stage, mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfcn_ffnet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 185\u001b[0m     loss, prob_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcn_ffnet_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\models\\lightning_module.py:151\u001b[0m, in \u001b[0;36mBreastSegmentationModel.fcn_ffnet_step\u001b[1;34m(self, stage, image, mask, batch)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m output, out_fc, out_neigh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\models\\architectures.py:161\u001b[0m, in \u001b[0;36mFcnnFnet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    159\u001b[0m out_fc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 161\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x1)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\Desktop\\venus\\breast_segmentation\\models\\architectures.py:30\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\torch\\nn\\functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer_fcn_ffnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfcn_ffnet_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_thorax_sub_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_thorax_sub_val_loader\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:560\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:66\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 66\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\wandb\\sdk\\lib\\exit_hooks.py:36\u001b[0m, in \u001b[0;36mExitHooks.exit\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_code \u001b[38;5;241m=\u001b[39m code\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orig_exit\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_code\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
          ]
        }
      ],
      "source": [
        "trainer_fcn_ffnet_model.fit(\n",
        "    fcn_ffnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\pabli\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\venus-nCPuPPcI-py3.9\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1298be855e744400a4b3fb19fed518a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{   'test_acc_per_dataset_background': 0.0,\n",
            "    'test_acc_per_dataset_mass': 2.3241394956130534e-05,\n",
            "    'test_acc_per_image_background': 0.0,\n",
            "    'test_acc_per_image_mass': 2.3241396775119938e-05,\n",
            "    'test_accuracy': 2.3679915102547966e-05,\n",
            "    'test_dice_per_dataset_background': 0.0,\n",
            "    'test_dice_per_dataset_background_no_empty': 0.0,\n",
            "    'test_dice_per_dataset_mass': 4.647306923288852e-05,\n",
            "    'test_dice_per_dataset_mass_no_empty': 4.647306923288852e-05,\n",
            "    'test_dice_per_image_background': 0.0,\n",
            "    'test_dice_per_image_background_no_empty': 0.0,\n",
            "    'test_dice_per_image_mass': 4.640757470042445e-05,\n",
            "    'test_dice_per_image_mass_no_empty': 4.640757470042445e-05,\n",
            "    'test_iou_per_dataset_background': 0.0,\n",
            "    'test_iou_per_dataset_background_no_empty': 0.0,\n",
            "    'test_iou_per_dataset_mass': 2.3241394956130534e-05,\n",
            "    'test_iou_per_dataset_mass_no_empty': 2.3241394956130534e-05,\n",
            "    'test_iou_per_image_background': 0.0,\n",
            "    'test_iou_per_image_background_no_empty': 0.0,\n",
            "    'test_iou_per_image_mass': 2.3241396775119938e-05,\n",
            "    'test_iou_per_image_mass_no_empty': 2.3241396775119938e-05,\n",
            "    'test_loss': 1.2145053148269653,\n",
            "    'test_mean_dice_per_dataset': 2.3641594452783465e-05,\n",
            "    'test_mean_dice_per_dataset_no_empty': 2.3641594452783465e-05,\n",
            "    'test_mean_dice_per_image': 2.3641594452783465e-05,\n",
            "    'test_mean_dice_per_image_no_empty': 2.3641594452783465e-05,\n",
            "    'test_mean_iou_per_dataset': 1.1839957551273983e-05,\n",
            "    'test_mean_iou_per_dataset_no_empty': 1.1839957551273983e-05,\n",
            "    'test_mean_iou_per_image': 1.1839957551273983e-05,\n",
            "    'test_mean_iou_per_image_no_empty': 1.1839957551273983e-05,\n",
            "    'test_per_dataset_dice': 4.7358702431665733e-05,\n",
            "    'test_per_dataset_iou': 2.3679915102547966e-05,\n",
            "    'test_per_image_dice': 4.728318890556693e-05,\n",
            "    'test_per_image_iou': 2.3679915102547966e-05,\n",
            "    'test_precision': 0.5000118613243103,\n",
            "    'test_recall': 0.5}\n"
          ]
        }
      ],
      "source": [
        "fcn_ffnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_fcn_ffnet_model.best_model_path,\n",
        "    t_loss=\"crossentropy2d\" ,\n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics = trainer_fcn_ffnet_model.test(\n",
        "    fcn_ffnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Swin-UNETR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "swin_unetr_model = BreastSegmentationModel(\n",
        "    arch=\"swin_unetr\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\",  # Use string instead of instantiating the class\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256, \n",
        "    in_channels=1, \n",
        "    out_classes=1, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_swin = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_swin_unetr_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='swin-unetr-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_swin_unetr_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_swin, cc_swin_unetr_model],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_swin_unetr_model.fit(\n",
        "    swin_unetr_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "swin_unetr_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_swin_unetr_model.best_model_path,\n",
        "    t_loss=\"crossentropy2d\", \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_swin = trainer_swin_unetr_model.test(\n",
        "    swin_unetr_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_swin[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Unet++\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "unetplusplus_model = BreastSegmentationModel(\n",
        "    arch=\"unetplusplus\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\",  # Use string instead of instantiating the class\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256, \n",
        "    in_channels=1, \n",
        "    out_classes=1, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_unetpp = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_unetplusplus_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='unetplusplus-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_unetplusplus_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_unetpp, cc_unetplusplus_model],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_unetplusplus_model.fit(\n",
        "    unetplusplus_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unetplusplus_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_unetplusplus_model.best_model_path,\n",
        "    t_loss=\"unetplusplus_loss\", \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_unetpp = trainer_unetplusplus_model.test(\n",
        "    unetplusplus_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_unetpp[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training SegNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "segnet_model = BreastSegmentationModel(\n",
        "    arch=\"segnet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\",  # Use string instead of instantiating the class\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256, \n",
        "    in_channels=1, \n",
        "    out_classes=1, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_segnet = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_segnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='segnet-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_segnet_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_segnet, cc_segnet_model],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_segnet_model.fit(\n",
        "    segnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_segnet_model.best_model_path,\n",
        "    t_loss=\"crossentropy2d\", \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_segnet = trainer_segnet_model.test(\n",
        "    segnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_segnet[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Skinny\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skinny_loss = \"dice_ce\"\n",
        "skinny_model = BreastSegmentationModel(\n",
        "    arch=\"skinny\",\n",
        "    encoder_name=None,\n",
        "    loss_function=skinny_loss,  # Use string for DiceCELoss\n",
        "    loss_kwargs={\"sigmoid\": True, \"lambda_dice\": 0.5, \"lambda_ce\": 0.5},\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256,\n",
        "    in_channels=1,\n",
        "    out_classes=1,\n",
        "    batch_size=batch_size,\n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "# Early stopping for SkinnyNet\n",
        "es_skinny = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "# Model checkpoint for SkinnyNet\n",
        "cc_skinny_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    dirpath=\"./checkpoints/\",\n",
        "    filename=\"skinny_best\",\n",
        "    auto_insert_metric_name=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer for SkinnyNet\n",
        "trainer_skinny_model = L.Trainer(\n",
        "    max_epochs=100,\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    callbacks=[es_skinny, cc_skinny_model],\n",
        "    deterministic=True,\n",
        "    precision=16\n",
        ")\n",
        "\n",
        "# Train SkinnyNet\n",
        "trainer_skinny_model.fit(\n",
        "    skinny_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best SkinnyNet model and test\n",
        "skinny_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_skinny_model.best_model_path,\n",
        "    t_loss=skinny_loss, \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_skinny = trainer_skinny_model.test(\n",
        "    skinny_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_skinny[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training ResNet-UNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = \"resnet50\"\n",
        "resnet_model = BreastSegmentationModel(\n",
        "    arch=\"UNet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"dice\",  # Use string for DiceLoss\n",
        "    loss_kwargs={\"sigmoid\": True},\n",
        "    use_boundary_loss=False,\n",
        "    img_size=256, \n",
        "    in_channels=1, \n",
        "    out_classes=1, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_resnet = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=10)\n",
        "\n",
        "cc_resnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='resnet-unet-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_resnet_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='gpu',\n",
        "    max_epochs=1000,\n",
        "    callbacks=[es_resnet, cc_resnet_model],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_resnet_model.fit(\n",
        "    resnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_resnet_model.best_model_path,\n",
        "    t_loss=\"dice\" \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_resnet = trainer_resnet_model.test(\n",
        "    resnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_resnet[0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venus-nCPuPPcI-py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}