{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETUP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installs & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "import tempfile\n",
        "import random\n",
        "import warnings\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "# Third-party libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import albumentations as A\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skimage import filters\n",
        "from skimage.measure import label as label_fn, regionprops\n",
        "from skimage import morphology\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# MONAI related imports\n",
        "from monai.config import print_config\n",
        "from monai.networks.nets import UNet, SwinUNETR, BasicUNetPlusPlus\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.transforms import (\n",
        "    AsDiscrete, AsDiscreted, EnsureChannelFirstd, Compose, CropForegroundd,\n",
        "    LoadImaged, Orientationd, RandCropByPosNegLabeld, SaveImaged, ScaleIntensityRanged,\n",
        "    Spacingd, Invertd, ResizeWithPadOrCropd, Resized, MapTransform, ScaleIntensityd,\n",
        "    LabelToContourd, ForegroundMaskd, HistogramNormalized, RandFlipd, RandGridDistortiond,\n",
        "    RandHistogramShiftd, RandRotated\n",
        ")\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.utils.type_conversion import convert_to_numpy\n",
        "\n",
        "# PyTorch Lightning related imports\n",
        "import lightning.pytorch as L\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from lightning.pytorch import seed_everything\n",
        "\n",
        "from natsort import natsorted, ns\n",
        "from PIL import Image\n",
        "from numpy import einsum\n",
        "from torch.utils.data import default_collate\n",
        "import psutil\n",
        "from typing import List\n",
        "import monai\n",
        "\n",
        "# Import modules\n",
        "from breast_segmentation.config.settings import config\n",
        "from breast_segmentation.utils.seed import set_deterministic_mode, seed_worker, reseed\n",
        "from breast_segmentation.data.dataset import (\n",
        "    get_image_label_files, create_data_dicts\n",
        ")\n",
        "from breast_segmentation.data import custom_collate_no_patches\n",
        "from breast_segmentation.transforms.compose import Preprocess\n",
        "from breast_segmentation.models.lightning_module import BreastSegmentationModel\n",
        "from breast_segmentation.models.architectures import get_model\n",
        "from breast_segmentation.metrics.losses import get_loss_function, CrossEntropy2d, compute_class_weight, AsymmetricUnifiedFocalLoss\n",
        "\n",
        "from breast_segmentation.data.private_dataset import (\n",
        "    PATIENT_INFO, get_filenames, get_train_val_test_dicts, PATIENTS_TO_EXCLUDE\n",
        ")\n",
        "\n",
        "\n",
        "# Import additional loss functions used in original\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "\n",
        "# Set precision for matmul operations and print MONAI config\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "print_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix checkpoint directory reference for private dataset baselines\n",
        "checkpoints_dir = config.checkpoints_dir_private\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "print(f\"Baselines Training - Using checkpoint directory: {checkpoints_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "patient_ids = list(PATIENT_INFO.keys())\n",
        "\n",
        "# Apply exclusions (exactly as in reference notebook)\n",
        "print(f\"Initial patients from PATIENT_INFO: {len(patient_ids)}\")\n",
        "print(f\"Patients to exclude: {PATIENTS_TO_EXCLUDE}\")\n",
        "patient_ids = [pid for pid in patient_ids if pid not in PATIENTS_TO_EXCLUDE]\n",
        "print(f\"Patients after exclusion: {len(patient_ids)}\")\n",
        "\n",
        "# Data split using original train_test_split\n",
        "SEED = config.SEED \n",
        "dataset_base_path = config.DATASET_BASE_PATH_PRIVATE\n",
        "x_train_val, x_test = train_test_split(patient_ids, test_size=0.2, random_state=SEED)\n",
        "x_train, x_val = train_test_split(x_train_val, test_size=0.25, random_state=SEED)\n",
        "\n",
        "\n",
        "print(\"Creating data dictionaries with filtering logic...\")\n",
        "train_dicts, val_dicts, test_dicts = get_train_val_test_dicts(dataset_base_path, x_train, x_val, x_test)\n",
        "\n",
        "print(f\"\\ndata:\")\n",
        "print(f\"  Training samples: {len(train_dicts)}\")\n",
        "print(f\"  Validation samples: {len(val_dicts)}\")\n",
        "print(f\"  Test samples: {len(test_dicts)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - using config parameters\n",
        "batch_size = config.BATCH_SIZE\n",
        "num_workers = config.NUM_WORKERS\n",
        "checkpoints_dir = config.checkpoints_dir_private\n",
        "get_boundaryloss = False\n",
        "\n",
        "# Ensure checkpoints directory exists\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "g = set_deterministic_mode(config.SEED)\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Number of workers: {num_workers}\")\n",
        "print(f\"Checkpoints directory: {checkpoints_dir}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Private Dataset Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define subtracted images path prefixes\n",
        "sub_third_images_path_prefixes = (\"Dataset-arrays-4-FINAL\", \"Dataset-arrays-FINAL\")\n",
        "\n",
        "# Create transforms for statistics calculation\n",
        "statistics_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.NumpyReader()\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='statistics',  \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        get_patches=False\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"Statistics transforms created for private dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset for statistics calculation\n",
        "statistics_ds_private = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=statistics_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "statistics_loader_private = DataLoader(\n",
        "    statistics_ds_private, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  \n",
        ")\n",
        "\n",
        "print(\"Statistics dataset and loader created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mean and std for normalization\n",
        "def get_mean_std_dataloader(dataloader, masked=False):\n",
        "    \"\"\"Calculate mean and std from dataloader.\"\"\"\n",
        "    sum_of_images = 0.0\n",
        "    sum_of_squares = 0.0\n",
        "    num_pixels = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        if batch is not None:\n",
        "            image = batch[\"image\"]\n",
        "      \n",
        "            if masked:\n",
        "                mask = image > 0.0\n",
        "                image = image[mask]\n",
        "      \n",
        "            sum_of_images += image.sum()\n",
        "            sum_of_squares += (image ** 2).sum()\n",
        "            num_pixels += image.numel()\n",
        "        else:\n",
        "            print(\"batch is None\")\n",
        "    \n",
        "    mean = sum_of_images / num_pixels\n",
        "    std_dev = (sum_of_squares / num_pixels - mean ** 2) ** 0.5\n",
        "\n",
        "    print(f'Mean: {mean}, Standard Deviation: {std_dev}')\n",
        "    return mean.item(), std_dev.item()\n",
        "\n",
        "mean_private, std_private = get_mean_std_dataloader(statistics_loader_private)\n",
        "print(f\"Calculated - Mean: {mean_private}, Standard Deviation: {std_private}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_no_thorax_third_sub, std_no_thorax_third_sub = 43.14976119995117, 172.67039489746094"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final transforms with calculated statistics\n",
        "test_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='test',  \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_private, \n",
        "        divisor=std_private, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])\n",
        "\n",
        "train_transforms_private = Compose([\n",
        "    LoadImaged(\n",
        "        keys=[\"image\", \"label\"], \n",
        "        image_only=False, \n",
        "        reader=monai.data.PILReader(converter=lambda image: image.convert(\"L\"))\n",
        "    ),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    monai.transforms.Rotate90d(keys=[\"image\", \"label\"]),\n",
        "    Preprocess(\n",
        "        keys=None, \n",
        "        mode='train', \n",
        "        dataset=\"private\", \n",
        "        subtracted_images_path_prefixes=sub_third_images_path_prefixes, \n",
        "        subtrahend=mean_private, \n",
        "        divisor=std_private, \n",
        "        get_patches=False,\n",
        "        get_boundaryloss=get_boundaryloss\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets (use original naming convention)\n",
        "train_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=train_dicts, \n",
        "    transform=train_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=val_dicts, \n",
        "    transform=test_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_ds_no_thorax_third_sub = CacheDataset(\n",
        "    data=test_dicts, \n",
        "    transform=test_transforms_private,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "no_thorax_sub_train_loader = DataLoader(\n",
        "    train_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=True, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches  \n",
        ")\n",
        "\n",
        "no_thorax_sub_val_loader = DataLoader(\n",
        "    val_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches)\n",
        "\n",
        "no_thorax_sub_test_loader = DataLoader(\n",
        "    test_ds_no_thorax_third_sub, \n",
        "    batch_size=batch_size, \n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g, \n",
        "    shuffle=False, \n",
        "    drop_last=False,\n",
        "    collate_fn=custom_collate_no_patches )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample batch\n",
        "i = next(iter(no_thorax_sub_train_loader))[\"image\"]\n",
        "print(i.shape)\n",
        "plt.imshow(i[0,0], cmap='gray')\n",
        "plt.title('Sample from training data')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training FCN-FFNET\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "fcn_ffnet_model = BreastSegmentationModel(\n",
        "    arch=\"fcn_ffnet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\", \n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0], \n",
        "    in_channels=config.IN_CHANNELS, \n",
        "    out_classes=config.OUT_CHANNELS, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "cc_fcn_ffnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='unet-clahe--mit2-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "trainer_fcn_ffnet_model = L.Trainer(\n",
        "    devices = 1,\n",
        "    accelerator='auto',\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    callbacks=[es, cc_fcn_ffnet_model],\n",
        "    log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
        "    gradient_clip_val=config.GRADIENT_CLIP_VAL,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_fcn_ffnet_model.fit(\n",
        "    fcn_ffnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fcn_ffnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_fcn_ffnet_model.best_model_path,\n",
        "    loss_function=\"crossentropy2d\" ,\n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics = trainer_fcn_ffnet_model.test(\n",
        "    fcn_ffnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Swin-UNETR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "swin_unetr_model = BreastSegmentationModel(\n",
        "    arch=\"swin_unetr\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function='soft_dice',\n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0], \n",
        "    in_channels=config.IN_CHANNELS, \n",
        "    out_classes=config.OUT_CHANNELS, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_swin = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "cc_swin_unetr_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='swin-unetr-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_swin_unetr_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='auto',\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    callbacks=[es_swin, cc_swin_unetr_model],\n",
        "    log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
        "    gradient_clip_val=config.GRADIENT_CLIP_VAL,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_swin_unetr_model.fit(\n",
        "    swin_unetr_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "swin_unetr_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_swin_unetr_model.best_model_path,\n",
        "    loss_function='soft_dice',\n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_swin = trainer_swin_unetr_model.test(\n",
        "    swin_unetr_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_swin[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Unet++\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "unetplusplus_model = BreastSegmentationModel(\n",
        "    arch=\"unetplusplus\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"dice_ce\",\n",
        "    loss_kwargs={\"sigmoid\": True, \"lambda_dice\": 0.5, \"lambda_ce\": 0.5},\n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0], \n",
        "    in_channels=config.IN_CHANNELS, \n",
        "    out_classes=config.OUT_CHANNELS, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_unetpp = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "cc_unetplusplus_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='unetplusplus-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_unetplusplus_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='auto',\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    callbacks=[es_unetpp, cc_unetplusplus_model],\n",
        "    log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
        "    gradient_clip_val=config.GRADIENT_CLIP_VAL,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_unetplusplus_model.fit(\n",
        "    unetplusplus_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unetplusplus_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_unetplusplus_model.best_model_path,\n",
        "    loss_function=\"dice_ce\",\n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_unetpp = trainer_unetplusplus_model.test(\n",
        "    unetplusplus_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_unetpp[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training SegNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = None\n",
        "segnet_model = BreastSegmentationModel(\n",
        "    arch=\"segnet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"crossentropy2d\",  \n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0], \n",
        "    in_channels=config.IN_CHANNELS, \n",
        "    out_classes=config.OUT_CHANNELS, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_segnet = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "cc_segnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='segnet-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_segnet_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='auto',\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    callbacks=[es_segnet, cc_segnet_model],\n",
        "    log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
        "    gradient_clip_val=config.GRADIENT_CLIP_VAL,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_segnet_model.fit(\n",
        "    segnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_segnet_model.best_model_path,\n",
        "    loss_function=\"crossentropy2d\", \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_segnet = trainer_segnet_model.test(\n",
        "    segnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_segnet[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Skinny\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skinny_model = BreastSegmentationModel(\n",
        "    arch=\"skinny\",\n",
        "    encoder_name=None,\n",
        "    loss_function=\"dice_ce\",\n",
        "    loss_kwargs={\"sigmoid\": True, \"lambda_dice\": 0.5, \"lambda_ce\": 0.5},\n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0],\n",
        "    in_channels=config.IN_CHANNELS,\n",
        "    out_classes=config.OUT_CHANNELS,\n",
        "    batch_size=batch_size,\n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "# Early stopping for SkinnyNet\n",
        "es_skinny = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "# Model checkpoint for SkinnyNet\n",
        "cc_skinny_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    dirpath=\"./checkpoints/\",\n",
        "    filename=\"skinny_best\",\n",
        "    auto_insert_metric_name=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer for SkinnyNet\n",
        "trainer_skinny_model = L.Trainer(\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    callbacks=[es_skinny, cc_skinny_model],\n",
        "    deterministic=True,\n",
        "    precision=16\n",
        ")\n",
        "\n",
        "# Train SkinnyNet\n",
        "trainer_skinny_model.fit(\n",
        "    skinny_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best SkinnyNet model and test\n",
        "skinny_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_skinny_model.best_model_path,\n",
        "    loss_function=\"dice_ce\", \n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_skinny = trainer_skinny_model.test(\n",
        "    skinny_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_skinny[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training ResNet-UNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = reseed()\n",
        "ENCODER_NAME = \"resnet50\"\n",
        "resnet_model = BreastSegmentationModel(\n",
        "    arch=\"UNet\", \n",
        "    encoder_name=ENCODER_NAME, \n",
        "    loss_function=\"dice\",  \n",
        "    loss_kwargs={\"sigmoid\": True},\n",
        "    use_boundary_loss=False,\n",
        "    img_size = config.IMAGE_SIZE[0], \n",
        "    in_channels=config.IN_CHANNELS, \n",
        "    out_classes=config.OUT_CHANNELS, \n",
        "    batch_size=batch_size, \n",
        "    len_train_loader=len(train_ds_no_thorax_third_sub)//batch_size\n",
        ")\n",
        "\n",
        "es_resnet = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "cc_resnet_model = ModelCheckpoint(\n",
        "    monitor=\"valid_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    filename='resnet-unet-{epoch:02d}-{valid_loss:.2f}',\n",
        "    dirpath=checkpoints_dir,\n",
        "    auto_insert_metric_name=False\n",
        ")\n",
        "\n",
        "\n",
        "trainer_resnet_model = L.Trainer(\n",
        "    devices=1,\n",
        "    accelerator='auto',\n",
        "    max_epochs=config.MAX_EPOCHS,\n",
        "    callbacks=[es_resnet, cc_resnet_model],\n",
        "    log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
        "    gradient_clip_val=config.GRADIENT_CLIP_VAL,\n",
        "    num_sanity_val_steps=1,\n",
        "    deterministic=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_resnet_model.fit(\n",
        "    resnet_model,\n",
        "    train_dataloaders=no_thorax_sub_train_loader,\n",
        "    val_dataloaders=no_thorax_sub_val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet_model = BreastSegmentationModel.load_from_checkpoint(\n",
        "    cc_resnet_model.best_model_path,\n",
        "    loss_function=\"dice\",\n",
        "    boundaryloss=False\n",
        ")\n",
        "test_metrics_resnet = trainer_resnet_model.test(\n",
        "    resnet_model, \n",
        "    dataloaders=no_thorax_sub_test_loader, \n",
        "    verbose=False\n",
        ")\n",
        "pp.pprint(test_metrics_resnet[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venus-nCPuPPcI-py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
